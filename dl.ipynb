{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('dmenv': conda)",
   "display_name": "Python 3.8.5 64-bit ('dmenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "7443be6333979a5671edb97a6208c12f43c7c42bc49d43d9a0706d3198065d4b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path,listdir\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "import requests\n",
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pytz\n",
    "\n",
    "local_tz = 'Asia/Almaty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curtime=pytz.timezone(local_tz).localize(datetime.strptime('2000-01-01 '+'23:55', '%Y-%m-%d %H:%M'))\n",
    "curtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1602874800.0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "datetime(2020, 10, 17, 1, 0).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 11, 1, 1, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "datetime.fromtimestamp(1604170800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getone(pattern, string):\n",
    "    m = pattern.search(string)\n",
    "    res = m.group(1) if m else ''\n",
    "    return res.strip()\n",
    "\n",
    "def clean(txt):\n",
    "    return txt.replace('&','').replace('\\'','').strip()\n",
    "\n",
    "def get_cookie_value(name):\n",
    "    return [x['value'] for x in cookies if x['name']==name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url='https://sofascore.com/'\n",
    "api_url='https://api.sofascore.com/api/v1/'\n",
    "\n",
    "def generate_headers():\n",
    "    return {\n",
    "            \"Accept\": \"*/*\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "            \"Host\": \"api.sofascore.com\",\n",
    "            \"Origin\": \"https://www.sofascore.com\",\n",
    "            \"Referer\": referer,\n",
    "            \"TE\": \"Trailers\",\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0\"\n",
    "        }\n",
    "\n",
    "def load_match_info(did, isft):\n",
    "    load_json('lineups',did, headers)\n",
    "    load_json('votes',did, headers, isft=isft)\n",
    "    if isft==1:\n",
    "        load_json('incidents',did, headers)\n",
    "        load_json('graph',did, headers)\n",
    "    #load_json('best-players',did, headers)\n",
    "    #load_json('event',did, headers)\n",
    "    #load_json('statistics',did, headers)\n",
    "    #load_json('h2h',did, headers)\n",
    "    #load_json('pregame-form',did, headers)\n",
    "    #load_json('winning-odds',did, headers)\n",
    "\n",
    "#\n",
    "\n",
    "def load_json(fn, did, headers, isft=0):\n",
    "    file_name='raw/{}_{}_{:%Y-%m-%d-%H%M}.json'.format(fn, did, datetime.now()) if fn=='votes' else f'raw/{fn}_{did}.json'\n",
    "    if not path.exists(file_name) or (fn=='votes' and isft==0):\n",
    "        script='' if fn=='event' else '/provider/1/'+fn if fn=='winning-odds' else '/'+fn\n",
    "        link=f'{api_url}event/{did}{script}'\n",
    "        r = requests.get(link, headers=headers)\n",
    "        if r.status_code==200:\n",
    "            with open(file_name, 'w+', encoding='utf8') as f:\n",
    "                f.write(r.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='data/matches.csv'\n",
    "df_matches=pd.read_csv(file_name, index_col=None)\n",
    "#SERVER_TZ = 'UTC'\n",
    "#df_matches['ts']=pd.DatetimeIndex(pd.to_datetime(df_matches['startTimestamp'], unit='s')).tz_localize(SERVER_TZ)\n",
    "df_matches=df_matches.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=['india', 'peru', 'south-africa', 'germany-amateur', 'saudi-arabia', 'united-arab-emirates']\n",
    "df_matches=df_matches.loc[~df_matches['country'].isin(exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.to_csv('data/matches1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches_new=pd.read_csv('data/matches1.csv', index_col=None).set_index('id')\n",
    "df_matches=pd.read_csv('data/matches.csv', index_comatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.update(df_matches_new[['awayScoreHT','awayScoreET','homeScoreET','awayScoreFT','homeScoreFT','status','winnerCode','homeScoreHT']])\n",
    "df_matches['id'] = df_matches.index\n",
    "df_matches_new['id'] = df_matches_new.index\n",
    "matchespd.concat([df_matches,df_matches_new]).drop_duplicates(subset='id', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_TZ = 'Asia/Almaty'\n",
    "df_matches['ts'].apply(lambda d: d.astimezone(pytz.timezone(LOCAL_TZ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid_countries=['saudi-arabia', 'chile']\n",
    "PROXY = \"127.0.0.1:9051\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "\n",
    "webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
    "    \"socksProxy\": PROXY,\n",
    "    \"socksVersion\": 5,\n",
    "    \"proxyType\": \"MANUAL\",\n",
    "}\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--proxy-server=socks5://' + PROXY)\n",
    "#chrome = webdriver.Chrome(executable_path=r'../lib/chromedriver.exe', options=options)\n",
    "firefox = webdriver.Firefox(executable_path=r'../lib/geckodriver.exe')\n",
    "\n",
    "firefox.get(\"https://www.sofascore.com/\")\n",
    "#chrome.get(\"https://www.sofascore.com/\")\n",
    "\n",
    "referer=firefox.current_url\n",
    "cookies=firefox.get_cookies()\n",
    "html = firefox.page_source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = firefox.page_source\n",
    "\n",
    "dids=[]\n",
    "\n",
    "keys=['svg','path','rect','span']\n",
    "for key in keys:\n",
    "    html=re.sub(f'<{key}[^>]+>','',html)\n",
    "    html=html.replace(f'</{key}>','')\n",
    "html=re.sub(r'<div data-change-key=\"status\"[^>]+>-</div>','',html)\n",
    "html=html.replace(f'</div>','')\n",
    "\n",
    "pChamp = re.compile(r'<a href=\"/tournament/football/([^/]+)/([^/]+)/(\\d+)\">([^<]+)</a>')\n",
    "pMatch = re.compile(r'<a data-id=\"(\\d+)\" class=\"[^\"]+\" href=\"([^\"]+)\"><div><div[^>]+><div[^>]+><div[^>]+>([^<]+)<div[^>]+>([^<]+)<div[^>]+><div[^>]+><div[^>]+>([^<]+)<div[^>]+>([^<]+)<div[^>]+><div[^>]+><div[^>]+><div[^>]+>([^<]*)<div[^>]+>([^<]*)')\n",
    "pMatch1 = re.compile(r'<a data-id=\"(\\d+)\" class=\"[^\"]+\" href=\"([^\"]+)\"><div><div[^>]+><div title=\"([^\"]+)\"[^>]+><div[^>]+>(<div[^>]+>)?([^<]+)')\n",
    "pMatch2 = re.compile(r'[^>]+><div[^>]+>([^<]+)<div[^>]+>([^<]+)<div[^>]+><div[^>]+><div[^>]+><div[^>]+>([^<]*)<div[^>]+>([^<]*)')\n",
    "parts = html.split('<div class=\"Section-sc-1a7xrsb-0 styles__CategoryImageSection-sc-7mecl8-8 hTnyYh\">')[1:-1]\n",
    "for part in parts:\n",
    "    if 'SofaScore ratings' in part:\n",
    "        m = pChamp.search(part)\n",
    "        if m:\n",
    "            country, champ_sname, champ_id, champ_name=m.groups()\n",
    "        else:\n",
    "            raise Exception('CHAMPS NOT FOUND IN\\n\\n'+part)\n",
    "        if country in avoid_countries:\n",
    "            continue\n",
    "        mm=part.split('</button></a>')[:-1]\n",
    "        print(country, champ_sname, champ_id, champ_name,'FOUND %s matches'%(len(mm)))\n",
    "        for match in mm:\n",
    "            if 'Canceled' in match or 'Postponed' in match:\n",
    "                print('Canceled or Postponed!!!')\n",
    "                continue\n",
    "\n",
    "            m = pMatch1.search(match)\n",
    "            if m:\n",
    "                match_did,match_link,match_status,_,match_time=m.groups()\n",
    "                print(match_did,match_link,match_status,match_time)\n",
    "                if match_time=='HT':\n",
    "                    continue\n",
    "            else:\n",
    "                raise Exception('MATCH NOT FOUND IN\\n\\n'+match)\n",
    "            pps=match.split('<div title=')[-1]\n",
    "            m = pMatch2.search(pps)\n",
    "            if m:\n",
    "                match_team1,match_team2,match_score1,match_score2=m.groups()\n",
    "                print(match_team1,match_team2,match_score1,match_score2)\n",
    "            else:\n",
    "                raise Exception('MATCH NOT FOUND IN PPS\\n\\n'+pps)\n",
    "            dids.append([country, champ_sname, champ_id, champ_name,match_did,match_link,match_time,match_status,match_team1,match_team2,match_score1,match_score2])\n",
    "matches=pd.DataFrame(data=dids, columns=['country', 'champ_sname', 'champ_id', 'champ_name','match_did','match_link','match_time','match_status','match_team1','match_team2','match_score1','match_score2'])\n",
    "matches.loc[matches['match_score1']=='','match_score1']=np.nan\n",
    "matches.loc[matches['match_score2']=='','match_score2']=np.nan\n",
    "matches['FT']=np.where(matches['match_score1'].isna(),0,1)\n",
    "dids=matches[['match_did','FT']].values\n",
    "np.random.shuffle(dids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=datetime.strptime('2020-10-31', '%Y-%m-%d')\n",
    "dstr='{:%Y-%m-%d}'.format(d)\n",
    "matches['ts']=matches['match_time'].apply(lambda x: pytz.timezone(local_tz).localize(datetime.strptime(f'{dstr} {x}', '%Y-%m-%d %H:%M')))\n",
    "matches.to_csv(f'raw/matches_{dstr}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_matches(arr):\n",
    "    l=len(arr)\n",
    "    if l>0:\n",
    "        did,isft=arr[0]\n",
    "        print(f'Loading {did},{isft} from {l}...', end='')\n",
    "        load_match_info(did, isft)\n",
    "        print(' done!')\n",
    "        time.sleep(random.uniform(1, 5))\n",
    "        load_matches(np.delete(arr, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_match_info(1399303, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=generate_headers()\n",
    "load_matches(dids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn='statistics'\n",
    "did=9091949\n",
    "script='' if fn=='event' else '/'+fn\n",
    "link=f'{api_url}event/{did}{script}'\n",
    "headers=generate_headers()\n",
    "r = requests.get(link, headers=headers)\n",
    "if r.status_code==200:\n",
    "    with open(f'raw/{fn}_{did}.json', 'w+', encoding='utf8') as f:\n",
    "        f.write(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = {'https': f'socks5://{PROXY}'}\n",
    "\n",
    "dates=[]\n",
    "d= datetime(2013, 1, 1)\n",
    "end_date= datetime(2020, 10, 28)\n",
    "\n",
    "while d<=end_date:\n",
    "    dates.append(d)\n",
    "    d+=timedelta(days=1)\n",
    "dates=np.array(dates) \n",
    "np.random.shuffle(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tor_new_identity():\n",
    "    with Controller.from_port(port=9052) as controller:\n",
    "        controller.authenticate()\n",
    "        #controller.authenticate(password=\"1234\")\n",
    "        controller.signal(Signal.NEWNYM)\n",
    "        controller.close()\n",
    "\n",
    "def load_days(test=False,c=0,n=0,max_load=random.randint(50, 100)):\n",
    "    global dates,r,dstr,proxies\n",
    "    l=len(dates)\n",
    "    if l>0:\n",
    "        dstr='{:%Y-%m-%d}'.format(dates[0])\n",
    "        link=f'https://api.sofascore.com/api/v1/sport/football/scheduled-events/{dstr}'\n",
    "        referer=f'https://www.sofascore.com/football/{dstr}'\n",
    "        print(f'Loading {dstr} from {l}...', end='')\n",
    "        headers=generate_headers()\n",
    "        r = requests.get(link, headers=headers, proxies=proxies)\n",
    "        if test:\n",
    "            print(r.status_code)\n",
    "        if r.status_code==200:\n",
    "            c=0\n",
    "            with open(f'raw/{dstr}.json', 'w+', encoding='utf8') as f:\n",
    "                f.write(r.text)\n",
    "            n+=1\n",
    "            if n>max_load:\n",
    "                tor_new_identity()\n",
    "                time.sleep(random.uniform(10, 20))\n",
    "                load_days()\n",
    "        else:\n",
    "            print(f'ERROR {r.status_code}!!! Obtaining new identity. Try # {c}.')\n",
    "            tor_new_identity()\n",
    "            time.sleep(random.uniform(10, 20))\n",
    "            c+=1\n",
    "            if c>10:\n",
    "                return \n",
    "            load_days(c=c)\n",
    "        c=0\n",
    "        print(f' done #{n} from the batch of {max_load}!')\n",
    "        time.sleep(random.uniform(1, 5))\n",
    "        dates=np.delete(dates, 0, 0)\n",
    "        if not test:\n",
    "            load_days(c=c,n=n,max_load=max_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "load_days(test=False)\n",
    "#len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn='winning-odds'\n",
    "did=9091949\n",
    "script='' if fn=='event' else '/provider/1/'+fn if fn=='winning-odds' else '/'+fn\n",
    "link=f'{api_url}event/{did}{script}'\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LOOP: [5510574 100 '2015-01-23 19:00:00+00:00']\n",
      "Loading 2015-01-23 5510574: votes..., graph... done.\n",
      "LOOP: [5509580 100 '2015-01-23 19:30:00+00:00']\n",
      "Loading 2015-01-23 5509580: votes..., graph... done.\n",
      "LOOP: [5934370 100 '2015-01-23 19:30:00+00:00']\n",
      "Loading 2015-01-23 5934370: votes..., graph... done.\n",
      "LOOP: [5555432 100 '2015-01-23 19:30:00+00:00']\n",
      "Loading 2015-01-23 5555432: votes..., graph... done.\n",
      "LOOP: [5587608 100 '2015-01-23 19:45:00+00:00']\n",
      "Loading 2015-01-23 5587608: votes..., graph... done.\n",
      "LOOP: [6576383 100 '2015-01-23 19:55:00+00:00']\n",
      "Loading 2015-01-23 6576383: votes..., graph... done.\n",
      "LOOP: [6571262 100 '2015-01-24 01:30:00+00:00']\n",
      "Loading 2015-01-24 6571262: votes..., graph... done.\n",
      "LOOP: [6571270 100 '2015-01-24 02:30:00+00:00']\n",
      "Loading 2015-01-24 6571270: votes..., graph... done.\n",
      "LOOP: [6571260 100 '2015-01-24 03:30:00+00:00']\n",
      "Loading 2015-01-24 6571260: votes..., graph... done.\n",
      "LOOP: [5578782 100 '2015-01-24 06:00:00+00:00']\n",
      "Loading 2015-01-24 5578782: votes..., graph... done.\n",
      "LOOP: [5578784 100 '2015-01-24 08:30:00+00:00']\n",
      "Loading 2015-01-24 5578784: votes..., graph... done.\n",
      "LOOP: [5722448 100 '2015-01-24 11:30:00+00:00']\n",
      "Loading 2015-01-24 5722448: votes..., graph... done.\n",
      "LOOP: [6576384 100 '2015-01-24 12:45:00+00:00']\n",
      "Loading 2015-01-24 6576384: votes..., graph... done.\n",
      "LOOP: [5587606 100 '2015-01-24 12:45:00+00:00']\n",
      "Loading 2015-01-24 5587606: votes..., graph... done.\n",
      "LOOP: [5510576 100 '2015-01-24 13:00:00+00:00']\n",
      "Loading 2015-01-24 5510576: votes..., graph... done.\n",
      "LOOP: [5510578 100 '2015-01-24 13:00:00+00:00']\n",
      "Loading 2015-01-24 5510578: votes..., graph... done.\n",
      "LOOP: [5774436 100 '2015-01-24 13:00:00+00:00']\n",
      "Loading 2015-01-24 5774436: votes..., graph... done.\n",
      "LOOP: [5722450 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5722450: votes..., graph... done.\n",
      "LOOP: [5934368 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934368: votes..., graph... done.\n",
      "LOOP: [5934372 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934372: votes..., graph... done.\n",
      "LOOP: [5934374 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934374: votes..., graph... done.\n",
      "LOOP: [5990068 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5990068: votes..., graph... done.\n",
      "LOOP: [5934376 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934376: votes..., graph... done.\n",
      "LOOP: [5934380 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934380: votes..., graph... done.\n",
      "LOOP: [5934384 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934384: votes..., graph... done.\n",
      "LOOP: [5934386 100 '2015-01-24 14:00:00+00:00']\n",
      "Loading 2015-01-24 5934386: votes..., graph... done.\n",
      "Reached maximum loads on this proxy. Changing...Saving df_matches...done\n",
      "LOOP: [5764492 100 '2015-01-24 15:00:00+00:00']\n",
      "Loading 2015-01-24 5764492: votes..., graph... done.\n",
      "LOOP: [6576386 100 '2015-01-24 15:00:00+00:00']\n",
      "Loading 2015-01-24 6576386: votes..., graph... done.\n",
      "LOOP: [6576382 100 '2015-01-24 15:00:00+00:00']\n",
      "Loading 2015-01-24 6576382: votes..., graph... done.\n",
      "LOOP: [5583928 100 '2015-01-24 15:00:00+00:00']\n",
      "Loading 2015-01-24 5583928: votes..., graph... done.\n",
      "LOOP: [5774438 100 '2015-01-24 15:15:00+00:00']\n",
      "Loading 2015-01-24 5774438: votes..., graph... done.\n",
      "LOOP: [5774440 100 '2015-01-24 15:15:00+00:00']\n",
      "Loading 2015-01-24 5774440: votes..., graph... done.\n",
      "LOOP: [5774446 100 '2015-01-24 15:15:00+00:00']\n",
      "Loading 2015-01-24 5774446: votes..., graph... done.\n",
      "LOOP: [5774450 100 '2015-01-24 15:15:00+00:00']\n",
      "Loading 2015-01-24 5774450: votes..., graph... done.\n",
      "LOOP: [6506370 100 '2015-01-24 16:00:00+00:00']\n",
      "Loading 2015-01-24 6506370: votes..., graph... done.\n",
      "LOOP: [5509574 100 '2015-01-24 16:00:00+00:00']\n",
      "Loading 2015-01-24 5509574: votes..., graph... done.\n",
      "LOOP: [5764500 100 '2015-01-24 17:00:00+00:00']\n",
      "Loading 2015-01-24 5764500: votes..., graph... done.\n",
      "LOOP: [5786132 100 '2015-01-24 17:00:00+00:00']\n",
      "Loading 2015-01-24 5786132: votes..., graph... done.\n",
      "LOOP: [5722458 100 '2015-01-24 17:00:00+00:00']\n",
      "Loading 2015-01-24 5722458: votes..., graph... done.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4527352efbb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#dp.load_days(ds, de)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#dp.load_days() # Process al files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_matches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\dev\\soccer\\data_provider.py\u001b[0m in \u001b[0;36mload_matches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[1;31m#print('LOOP:', data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_matches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\dev\\soccer\\data_provider.py\u001b[0m in \u001b[0;36m_load_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAUSE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data_provider import DataProvider\n",
    "ds='2014-01-01'\n",
    "de='2020-10-31'\n",
    "\n",
    "#ds='2020-04-05'\n",
    "#de='2020-04-05'\n",
    "\n",
    "dp=DataProvider()\n",
    "#dp.load_days(ds, de)\n",
    "#dp.load_days() # Process al files\n",
    "dp.load_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[5722456, 100, '2015-01-23 17:00:00+00:00'],\n",
       "       [5722456, 100, '2015-01-23 17:00:00+00:00'],\n",
       "       [5862752, 100, '2015-01-23 17:30:00+00:00'],\n",
       "       ...,\n",
       "       [8730283, 100, '2020-07-11 16:15:00+00:00'],\n",
       "       [8706609, 100, '2020-07-11 16:15:00+00:00'],\n",
       "       [8706619, 100, '2020-07-11 16:15:00+00:00']], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#matches=[x for x in dp.DATA['events'] if 'coverage' in x.keys()]\n",
    "dp.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[datetime.datetime(2014, 3, 11, 0, 0),\n",
       " datetime.datetime(2014, 3, 26, 0, 0),\n",
       " datetime.datetime(2014, 4, 15, 0, 0),\n",
       " datetime.datetime(2014, 5, 7, 0, 0),\n",
       " datetime.datetime(2014, 5, 28, 0, 0),\n",
       " datetime.datetime(2014, 6, 13, 0, 0),\n",
       " datetime.datetime(2014, 8, 10, 0, 0),\n",
       " datetime.datetime(2014, 10, 24, 0, 0),\n",
       " datetime.datetime(2015, 4, 12, 0, 0),\n",
       " datetime.datetime(2015, 4, 22, 0, 0),\n",
       " datetime.datetime(2015, 5, 4, 0, 0),\n",
       " datetime.datetime(2015, 6, 22, 0, 0),\n",
       " datetime.datetime(2015, 7, 8, 0, 0),\n",
       " datetime.datetime(2016, 2, 27, 0, 0),\n",
       " datetime.datetime(2016, 4, 11, 0, 0),\n",
       " datetime.datetime(2016, 8, 28, 0, 0),\n",
       " datetime.datetime(2016, 9, 23, 0, 0),\n",
       " datetime.datetime(2016, 10, 13, 0, 0),\n",
       " datetime.datetime(2016, 10, 17, 0, 0),\n",
       " datetime.datetime(2016, 12, 27, 0, 0),\n",
       " datetime.datetime(2017, 4, 5, 0, 0),\n",
       " datetime.datetime(2017, 4, 13, 0, 0),\n",
       " datetime.datetime(2017, 7, 31, 0, 0),\n",
       " datetime.datetime(2017, 8, 4, 0, 0),\n",
       " datetime.datetime(2017, 8, 24, 0, 0),\n",
       " datetime.datetime(2017, 10, 16, 0, 0),\n",
       " datetime.datetime(2017, 11, 22, 0, 0),\n",
       " datetime.datetime(2017, 12, 17, 0, 0),\n",
       " datetime.datetime(2018, 1, 21, 0, 0),\n",
       " datetime.datetime(2018, 5, 10, 0, 0),\n",
       " datetime.datetime(2018, 5, 24, 0, 0),\n",
       " datetime.datetime(2018, 6, 7, 0, 0),\n",
       " datetime.datetime(2018, 7, 18, 0, 0),\n",
       " datetime.datetime(2018, 8, 2, 0, 0),\n",
       " datetime.datetime(2018, 10, 14, 0, 0),\n",
       " datetime.datetime(2018, 11, 3, 0, 0),\n",
       " datetime.datetime(2018, 11, 9, 0, 0),\n",
       " datetime.datetime(2018, 11, 13, 0, 0),\n",
       " datetime.datetime(2018, 12, 5, 0, 0),\n",
       " datetime.datetime(2019, 2, 2, 0, 0),\n",
       " datetime.datetime(2019, 2, 24, 0, 0),\n",
       " datetime.datetime(2019, 2, 27, 0, 0),\n",
       " datetime.datetime(2019, 4, 28, 0, 0),\n",
       " datetime.datetime(2019, 5, 1, 0, 0),\n",
       " datetime.datetime(2019, 7, 2, 0, 0),\n",
       " datetime.datetime(2019, 7, 29, 0, 0),\n",
       " datetime.datetime(2019, 8, 5, 0, 0),\n",
       " datetime.datetime(2019, 10, 16, 0, 0),\n",
       " datetime.datetime(2020, 5, 17, 0, 0),\n",
       " datetime.datetime(2020, 5, 20, 0, 0),\n",
       " datetime.datetime(2020, 10, 8, 0, 0)]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "[datetime.strptime(f.replace('.json', ''), '%Y-%m-%d') for f in listdir('raw/')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='data/matches1.csv'\n",
    "dp.df_matches.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dp.COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import json\n",
    "file_name='raw/2016-08-28.json'\n",
    "with open(file_name, 'r', encoding='utf8') as f:\n",
    "    data=json.load(f)\n",
    "matches=[x for x in data['events'] if 'coverage' in x.keys()]\n",
    "matches=[x for x in matches if x['coverage']>-1]\n",
    "matches=[x for x in matches if not x['status']['code'] in [60,70]]\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in matches if not x['status']['code']==100 and not x['status']['code']==110 and not x['status']['code']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=[x for x in dp.data['events'] if 'coverage' in x.keys()]\n",
    "matches=[x for x in matches if x['coverage']>-1]\n",
    "matches=[x for x in matches if x['status']['code']==100 or x['status']['code']==110]\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[  {'tournament' : x['tournament']['slug'],\n",
    "    'country' : x['tournament']['category']['slug'],\n",
    "    'round' : x['roundInfo']['round'] if 'roundInfo' in x.keys() else np.NaN,\n",
    "    'status' : x['status']['code'],\n",
    "    'homeTeam' : x['homeTeam']['name'],\n",
    "    'homeTeamShort' : x['homeTeam']['shortName'],\n",
    "    'awayTeam' : x['awayTeam']['name'],\n",
    "    'awayTeamShort' : x['awayTeam']['shortName'],\n",
    "    'homeScoreFT' : x['homeScore']['normaltime'] if 'normaltime' in x.keys() else np.NaN,\n",
    "    'homeScoreET' : x['homeScore']['current'] if 'current' in x.keys() else np.NaN,\n",
    "    'homeScoreHT' : x['homeScore']['period1'] if 'period1' in x.keys() else np.NaN,\n",
    "    'awayScoreFT' : x['awayScore']['normaltime'] if 'normaltime' in x.keys() else np.NaN,\n",
    "    'awayScoreET' : x['awayScore']['current'] if 'current' in x.keys() else np.NaN,\n",
    "    'awayScoreHT' : x['awayScore']['period1'] if 'period1' in x.keys() else np.NaN,\n",
    "    'id' : x['id'],\n",
    "    'startTimestamp' : x['startTimestamp'],\n",
    "    'coverage' : x['coverage'],\n",
    "    'winnerCode' : x['winnerCode']} for x in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_json('best-players',did, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "did=9091942\n",
    "load_match_info(did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}