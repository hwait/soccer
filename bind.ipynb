{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('mlenv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "12f2fd9a8da6c9ddda222d67ff20ee53b82617d5a9ac88eb47f60b586ce1b05e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path,listdir\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import random\n",
    "import pytz\n",
    "#from tqdm import tqdm\n",
    "import bz2\n",
    "import json\n",
    "import glob\n",
    "local_tz = 'UTC'\n",
    "from api.data_collector import DataCollector\n",
    "from api.bind import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'8805230'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "a='votes_8805230_2021-01-30-2221'\n",
    "a.split('_')[1][:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Empty DataFrame\nColumns: [team]\nIndex: []\n"
     ]
    }
   ],
   "source": [
    "dp=DataCollector()\n",
    "#df_sofa=dp._provide_sofa()\n",
    "df_sofa=dp._load_data()\n",
    "df_op=dp._provide_op()\n",
    "#df_elo=dp._provide_elo()\n",
    "df_op_=df_op[df_op['ds']>=df_sofa.ds.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "IN: Sofa=(806, 46), OP=(43392, 22)\n",
      "BOTH teams step: Binded=(295, 53), Total=(295, 53), Rest=(789, 48)\n",
      "First team step: Binded=(194, 53), Total=(489, 53), Rest=(773, 48), Excluded=(7, 48)\n",
      "Second team step: Binded=(109, 53), Total=(598, 53), Rest=(773, 48), Excluded=(9, 48)\n",
      "**** FIRST ITERATION ****\n",
      "T1 merged:  (773, 49)\n",
      "T2 merged:  (773, 50)\n",
      "IN: 773, BOTH: 7, ONLY T1: 37, ONLY T2: 30, NO BINDS: 699, OUT: 773\n",
      "IN: Sofa=(7, 50), OP=(43392, 22)\n",
      "Both teams step, exact dates: Binded=(0, 54), Total=(0, 54), Rest=(7, 51)\n",
      "Both teams step, within a day: Binded=(0, 54), Total=(0, 54), Rest=(7, 51)\n",
      "(33, 53)\n",
      "IN: Sofa=(37, 50), OP=(43392, 22)\n",
      "First team step, exact dates: Binded=(53, 54), Total=(53, 54), Rest=(34, 51)\n",
      "First team step, within a day: Binded=(0, 54), Total=(3, 54), Rest=(34, 51)\n",
      "(36, 53)\n",
      "IN: Sofa=(30, 50), OP=(43392, 22)\n",
      "Second team step, exact dates: Binded=(156, 54), Total=(156, 54), Rest=(25, 51)\n",
      "Second team step, within a day: Binded=(0, 54), Total=(5, 54), Rest=(25, 51)\n",
      "(41, 53)\n",
      "save (74, 12)\n",
      "save (41, 12)\n",
      "**** SECOND ITERATION ****\n",
      "save (82, 12)\n",
      "save (41, 12)\n",
      "T1 merged:  (773, 49)\n",
      "T2 merged:  (773, 50)\n",
      "IN: 773, BOTH: 18, ONLY T1: 34, ONLY T2: 28, NO BINDS: 693, OUT: 773\n",
      "IN: Sofa=(18, 50), OP=(43392, 22)\n",
      "Both teams step, exact dates: Binded=(209, 54), Total=(209, 54), Rest=(10, 51)\n",
      "Both teams step, within a day: Binded=(0, 54), Total=(8, 54), Rest=(10, 51)\n",
      "(41, 53)\n",
      "IN: Sofa=(34, 50), OP=(43392, 22)\n",
      "First team step, exact dates: Binded=(0, 54), Total=(0, 54), Rest=(34, 51)\n",
      "First team step, within a day: Binded=(0, 54), Total=(0, 54), Rest=(34, 51)\n",
      "(41, 53)\n",
      "IN: Sofa=(28, 50), OP=(43392, 22)\n",
      "Second team step, exact dates: Binded=(44, 54), Total=(44, 54), Rest=(26, 51)\n",
      "Second team step, within a day: Binded=(0, 54), Total=(2, 54), Rest=(26, 51)\n",
      "(43, 53)\n",
      "save (84, 12)\n",
      "save (43, 12)\n",
      "**** THIRD ITERATION ****\n",
      "save (86, 12)\n",
      "save (43, 12)\n",
      "T1 merged:  (773, 49)\n",
      "T2 merged:  (773, 50)\n",
      "IN: 773, BOTH: 22, ONLY T1: 34, ONLY T2: 29, NO BINDS: 688, OUT: 773\n",
      "IN: Sofa=(22, 50), OP=(43392, 22)\n",
      "Both teams step, exact dates: Binded=(253, 54), Total=(253, 54), Rest=(12, 51)\n",
      "Both teams step, within a day: Binded=(0, 54), Total=(10, 54), Rest=(12, 51)\n",
      "(43, 53)\n",
      "IN: Sofa=(34, 50), OP=(43392, 22)\n",
      "First team step, exact dates: Binded=(0, 54), Total=(0, 54), Rest=(34, 51)\n",
      "First team step, within a day: Binded=(0, 54), Total=(0, 54), Rest=(34, 51)\n",
      "(43, 53)\n",
      "IN: Sofa=(29, 50), OP=(43392, 22)\n",
      "Second team step, exact dates: Binded=(10, 54), Total=(10, 54), Rest=(28, 51)\n",
      "Second team step, within a day: Binded=(0, 54), Total=(1, 54), Rest=(28, 51)\n",
      "(44, 53)\n",
      "save (87, 12)\n",
      "save (44, 12)\n"
     ]
    }
   ],
   "source": [
    "ts=pytz.timezone(local_tz).localize(datetime.today()-timedelta(days=20))\n",
    "df_op_=df_op[df_op['ds']>=ts]\n",
    "df_sofa=df_sofa[df_sofa['ds']>=ts]\n",
    "df_sofa_binded, df_sofa_ = bind_full(df_sofa,df_op_)\n",
    "df_sofa_binded=bind_iteration('FIRST',df_sofa_binded,df_sofa_, df_op_)\n",
    "df_sofa_binded=bind_iteration('SECOND',df_sofa_binded,df_sofa_, df_op_)\n",
    "df_sofa_binded=bind_iteration('THIRD',df_sofa_binded,df_sofa_, df_op_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams=pd.read_csv('data/teams.csv', index_col=None).sort_values(by='op_t')\n",
    "mask = df_teams.duplicated(subset=['country','op_t'], keep=False)\n",
    "display(df_teams[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elo.team=df_elo.team.str.lower()\n",
    "df_elo=df_elo.rename(columns={'country':'code'})\n",
    "df_elo_teams=df_elo[['team','code','id']].drop_duplicates().sort_values(by='team')\n",
    "df_countries=pd.read_csv('data/elo/countries.csv', index_col=None)\n",
    "df_elo_teams=df_elo_teams.merge(df_countries, on='code', how='left')\n",
    "df_elo_teams.to_csv('data/elo/elo_teams.csv', index=False)\n",
    "df_elo_teams['first']=df_elo_teams['team'].apply(lambda x: x.split(' ')[0])\n",
    "df_elo_teams['last']=df_elo_teams['team'].apply(lambda x: x.split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams=pd.read_csv('data/teams.csv', index_col=None)\n",
    "df_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elo_merged=df_elo.merge(df_teams[['id','tid']], on='id', how='left').drop_duplicates()\n",
    "df_elo_merged=df_elo_merged.dropna()\n",
    "df_elo_merged"
   ]
  },
  {
   "source": [
    "# Today"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=DataCollector()\n"
   ]
  },
  {
   "source": [
    "# Load data\n",
    "## SofaScore"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries=pd.read_csv('data/sofa/countries.csv', index_col=None)\n",
    "df_countries['Name']=df_countries['Name'].str.lower()\n",
    "df_countries.columns=['country','countryCode']\n",
    "\n",
    "chars0=['ó','é','í','ş','ã','İ','ğ','ç','ü','É','â','Ç','õ','ł','ą','Ś','ø','ń','ț','å','Å','ß', 'æ', 'Ž','ş', 'ə','Ö','ı','á','î','ñ','ö','ź','ú','è','Ł','ę','Ş','ä','ë','ô','ș','ū','č','Š','Þ','ė','Ä','ă','ì','š','i','ć','ň','ž','ư','ơ','ê','à','ð','ő','Ü','ý','ď','Á','ř','Č','Ú']\n",
    "chars1=['o','e','i','s','a','I','g','c','u','E','a','C','o','l','a','s','o','n','t','a','A','ss','ae','Z','sh','a','O','i','a','i','n','o','z','u','e','L','e','S','a','e','o','s','u','c','S','P','e','A','a','i','s','i','c','n','z','u','o','e','a','d','o','U','y','d','A','r','C','U']\n",
    "dicUnicode2En=dict(zip(chars0, chars1))\n",
    "\n",
    "df_ss=pd.read_csv('data/sofa/matches_done.csv', index_col=None)\n",
    "df_ss['ts']=pd.to_datetime(df_ss['ts'])\n",
    "df_ss=df_ss.merge(df_countries, on='country', how='left')\n",
    "df_ss.loc[df_ss['country']=='england','countryCode']='GB'\n",
    "df_ss.loc[df_ss['country']=='scotland','countryCode']='GB'\n",
    "df_ss.loc[df_ss['country']=='czech-republic','countryCode']='CZ'\n",
    "df_ss.loc[df_ss['country']=='russia','countryCode']='RU'\n",
    "df_ss.loc[df_ss['country']=='usa','countryCode']='US'\n",
    "df_ss.loc[df_ss['homeTeamShort']=='???','homeTeamShort']='AEK Athens'\n",
    "df_ss.loc[df_ss['awayTeamShort']=='???','awayTeamShort']='AEK Athens'\n",
    "df_ss['homeTeamShortLow']=df_ss['homeTeamShort'].replace(dicUnicode2En, regex=True).replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "df_ss['awayTeamShortLow']=df_ss['awayTeamShort'].replace(dicUnicode2En, regex=True).replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "countries_of_interest=sorted(list(df_ss.country.unique()))\n",
    "countries_of_interest+=['']"
   ]
  },
  {
   "source": [
    "## Betfair"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bf=pd.read_csv('data/bf/bf_matches.csv', index_col=None)\n",
    "df_bf=df_bf[~df_bf['halfTime'].isna()]\n",
    "df_bf=df_bf[df_bf['halfTime']!='0']\n",
    "df_bf['inplayTime']=pd.to_datetime(df_bf['inplayTime'])\n",
    "df_bf['home_name_low']=df_bf['home_name'].replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "df_bf['away_name_low']=df_bf['away_name'].replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "\n",
    "df_countries=pd.read_csv('data/sofa/countries.csv', index_col=None)\n",
    "df_countries['Name']=df_countries['Name'].str.lower()\n",
    "df_countries.columns=['country','countryCode']\n",
    "df_bf=df_bf.merge(df_countries, on='countryCode', how='left')\n",
    "\n",
    "df_bf=df_bf[df_bf['countryCode']!='CS']\n",
    "df_bf.loc[df_bf['countryCode'].isna(),'country']=''\n",
    "countries_replacement={'united kingdom':'england', 'russian federation':'russia','united states':'usa','czech republic':'czech-republic','korea, republic of':'south-korea' }\n",
    "df_bf['country']=df_bf['country'].replace(countries_replacement)\n",
    "df_bf=df_bf.loc[df_bf['country'].isin(countries_of_interest)]"
   ]
  },
  {
   "source": [
    "## Fbref"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(x):\n",
    "    if x==0:\n",
    "        return ''\n",
    "    res=df_countries.loc[df_countries['comps'].str.contains(str(int(x))),'name']\n",
    "    if len(res.index)>0:\n",
    "        return res.values[0]\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "df_countries=pd.read_csv('data/fbref/countries.csv', index_col=None)\n",
    "df_countries['name']=df_countries['name'].str.lower()\n",
    "#df_countries.columns=['country','countryCode']\n",
    "\n",
    "df_fbref=pd.read_csv('data/fbref/matches_full.csv', index_col=None)\n",
    "df_fbref=df_fbref[~df_fbref['ds_venue'].isna()]\n",
    "df_fbref['ts']=df_fbref['ds_venue'].apply(lambda x: datetime.utcfromtimestamp(x))\n",
    "\n",
    "df_fbref['home_name_low']=df_fbref['team1'].replace(dicUnicode2En, regex=True).replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "df_fbref['away_name_low']=df_fbref['team2'].replace(dicUnicode2En, regex=True).replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "df_fbref['country_id']=df_fbref['country_id'].fillna(0)\n",
    "df_fbref['country']=df_fbref['country_id'].apply(lambda x: get_country(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([df_fbref.isna().sum(),df_fbref.isna().sum()/1230 ]).T"
   ]
  },
  {
   "source": [
    "## OP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        country                 name  cnt         clear\n",
       "46        chile     Colo Colo (Chi)   Chi     Colo Colo\n",
       "80      austria  Rapid Vienna (Aut)   Aut  Rapid Vienna\n",
       "287      france    Bordeaux W (Fra)   Fra    Bordeaux W\n",
       "361       spain       Melilla (Esp)   Esp       Melilla\n",
       "401       spain      Numancia (Esp)   Esp      Numancia\n",
       "...         ...                  ...  ...           ...\n",
       "143800    spain           RSD Alcala         RSD Alcala\n",
       "144125    world            Hienghene          Hienghene\n",
       "144223    spain              Chinato            Chinato\n",
       "145021    world             Bucaspor           Bucaspor\n",
       "145205   europe            Potsdam W          Potsdam W\n",
       "\n",
       "[6622 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>name</th>\n      <th>cnt</th>\n      <th>clear</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>46</th>\n      <td>chile</td>\n      <td>Colo Colo (Chi)</td>\n      <td>Chi</td>\n      <td>Colo Colo</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>austria</td>\n      <td>Rapid Vienna (Aut)</td>\n      <td>Aut</td>\n      <td>Rapid Vienna</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>france</td>\n      <td>Bordeaux W (Fra)</td>\n      <td>Fra</td>\n      <td>Bordeaux W</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>spain</td>\n      <td>Melilla (Esp)</td>\n      <td>Esp</td>\n      <td>Melilla</td>\n    </tr>\n    <tr>\n      <th>401</th>\n      <td>spain</td>\n      <td>Numancia (Esp)</td>\n      <td>Esp</td>\n      <td>Numancia</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>143800</th>\n      <td>spain</td>\n      <td>RSD Alcala</td>\n      <td></td>\n      <td>RSD Alcala</td>\n    </tr>\n    <tr>\n      <th>144125</th>\n      <td>world</td>\n      <td>Hienghene</td>\n      <td></td>\n      <td>Hienghene</td>\n    </tr>\n    <tr>\n      <th>144223</th>\n      <td>spain</td>\n      <td>Chinato</td>\n      <td></td>\n      <td>Chinato</td>\n    </tr>\n    <tr>\n      <th>145021</th>\n      <td>world</td>\n      <td>Bucaspor</td>\n      <td></td>\n      <td>Bucaspor</td>\n    </tr>\n    <tr>\n      <th>145205</th>\n      <td>europe</td>\n      <td>Potsdam W</td>\n      <td></td>\n      <td>Potsdam W</td>\n    </tr>\n  </tbody>\n</table>\n<p>6622 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "df_op=pd.read_csv('data/op/matches1.csv', index_col=None)\n",
    "df_op['home_name_low']=df_op['t1'].replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "df_op['away_name_low']=df_op['t2'].replace('[^a-zA-Z0-9 ]', '', regex=True).str.lower()\n",
    "df_op['ts']=pd.to_datetime(df_op['ds'], format='%y/%m/%d %H:%M')\n",
    "\n",
    "t1=df_op[['country','t1']].rename(columns={'t1': 'name'})\n",
    "t2=df_op[['country','t2']].rename(columns={'t2': 'name'})\n",
    "\n",
    "df_teams=pd.DataFrame(pd.concat([t1,t2], axis=0)).drop_duplicates()\n",
    "\n",
    "df_countries=pd.read_csv('data/op/countries.csv', index_col=None)\n",
    "countries=dict(zip(df_countries.abbr, df_countries.name.str.lower()))\n",
    "\n",
    "df_teams['cnt']=df_teams['name'].apply(lambda x: x.split('(')[1].replace(')','').strip() if '(' in x else '')\n",
    "df_teams1=df_teams.loc[df_teams['cnt'].str.len()>1]\n",
    "df_teams2=df_teams.loc[df_teams['cnt'].str.len()<1]\n",
    "df_teams1['country']=df_teams1.cnt.apply(lambda x: countries[x] if x in countries else 'other')\n",
    "df_teams=pd.concat([df_teams1,df_teams2],axis=0)\n",
    "df_teams['clear']=df_teams.name.apply(lambda x: x.split('(')[0].strip())\n",
    "df_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               clear   tid\n",
       "0       Boreham Wood  0000\n",
       "1           Dortmund  0001\n",
       "2       Barcelona SC  0002\n",
       "3      Cambridge Utd  0003\n",
       "4     Esteghlal F.C.  0004\n",
       "...              ...   ...\n",
       "4546       Coleraine  4546\n",
       "4547       Conquense  4547\n",
       "4548          Loures  4548\n",
       "4549           Qandi  4549\n",
       "4550        Chanmari  4550\n",
       "\n",
       "[4551 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clear</th>\n      <th>tid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Boreham Wood</td>\n      <td>0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dortmund</td>\n      <td>0001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Barcelona SC</td>\n      <td>0002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cambridge Utd</td>\n      <td>0003</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Esteghlal F.C.</td>\n      <td>0004</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4546</th>\n      <td>Coleraine</td>\n      <td>4546</td>\n    </tr>\n    <tr>\n      <th>4547</th>\n      <td>Conquense</td>\n      <td>4547</td>\n    </tr>\n    <tr>\n      <th>4548</th>\n      <td>Loures</td>\n      <td>4548</td>\n    </tr>\n    <tr>\n      <th>4549</th>\n      <td>Qandi</td>\n      <td>4549</td>\n    </tr>\n    <tr>\n      <th>4550</th>\n      <td>Chanmari</td>\n      <td>4550</td>\n    </tr>\n  </tbody>\n</table>\n<p>4551 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df_clear=pd.DataFrame(df_teams.clear.unique(), columns=['clear'])\n",
    "df_clear['tid'] = df_clear.index\n",
    "df_clear['tid'] = df_clear.tid.apply(lambda x: '{:04.0f}'.format(x))\n",
    "df_teams=df_teams.merge(df_clear, on=['clear'], how='left')\n",
    "df_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams=df_teams.merge(df_clear, on=['clear'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      name  clear\n",
       "tid              \n",
       "0165     3      3\n",
       "0619     3      3\n",
       "0798     3      3\n",
       "0846     3      3\n",
       "0909     3      3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>clear</th>\n    </tr>\n    <tr>\n      <th>tid</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0165</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0619</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0798</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0846</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>0909</th>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "gr=df_teams.groupby(['tid']).count()\n",
    "gr.loc[gr['clear']>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    name        clear   tid\n",
       "622          River Plate  River Plate  0619\n",
       "2453  River Plate (Arg)   River Plate  0619\n",
       "3995  River Plate (Uru)   River Plate  0619"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>clear</th>\n      <th>tid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>622</th>\n      <td>River Plate</td>\n      <td>River Plate</td>\n      <td>0619</td>\n    </tr>\n    <tr>\n      <th>2453</th>\n      <td>River Plate (Arg)</td>\n      <td>River Plate</td>\n      <td>0619</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>River Plate (Uru)</td>\n      <td>River Plate</td>\n      <td>0619</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df_teams[df_teams.tid=='0619']"
   ]
  },
  {
   "source": [
    "# Binding\n",
    "## SS - BF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_to_empty=['africa','asia','europe','north-central-america','south-america','world']\n",
    "def slice_df(df, cc, str1, str2, type='00'):\n",
    "    if cc in cc_to_empty:\n",
    "        cc=''\n",
    "    if type=='00':\n",
    "        return df.loc[(df['country']==cc) & (df['home_name_low']==str1) & (df['away_name_low']==str2)]\n",
    "    elif type=='10':\n",
    "        return df.loc[(df['country']==cc) & (df['home_name_low'].str.contains(str1)) & (df['away_name_low']==str2)]\n",
    "    elif type=='01':\n",
    "        return df.loc[(df['country']==cc) & (df['home_name_low']==str1) & (df['away_name_low'].str.contains(str2))]\n",
    "    else:\n",
    "        return df.loc[(df['country']==cc) & (df['home_name_low'].str.contains(str1)) & (df['away_name_low'].str.contains(str2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "binds=[]\n",
    "d= datetime(2015, 5, 1)\n",
    "end_date= datetime(2020, 11, 1)\n",
    "while d<end_date:\n",
    "    print(d)\n",
    "    dloc=pytz.timezone(local_tz).localize(d)\n",
    "    df_ss_day=df_ss[(df_ss['ts']>=dloc) & (df_ss['ts']<dloc+timedelta(days=1))]\n",
    "    df_bf_day=df_bf[(df_bf['inplayTime']>=d) & (df_bf['inplayTime']<d+timedelta(days=1))]\n",
    "    for row in df_ss_day.itertuples(index=False):\n",
    "        home_parts=row.homeTeamShortLow.split(' ')\n",
    "        away_parts=row.awayTeamShortLow.split(' ')\n",
    "        df_bf_slice=slice_df(df_bf_day, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='00')\n",
    "        if len(df_bf_slice.index)!=1:\n",
    "            df_bf_slice=slice_df(df_bf_day, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='10')\n",
    "        if len(df_bf_slice.index)!=1:\n",
    "            df_bf_slice=slice_df(df_bf_day, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='01')\n",
    "        if len(df_bf_slice.index)!=1:\n",
    "            df_bf_slice=slice_df(df_bf_day, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='11')\n",
    "        if len(df_bf_slice.index)!=1 and ' ' in row.homeTeamShortLow:\n",
    "            homeFirst=home_parts[0]\n",
    "            homeLast=home_parts[-1]\n",
    "            if len(homeFirst)>2:\n",
    "                df_bf_slice=slice_df(df_bf_day, row.country, homeFirst, row.awayTeamShortLow, type='10')\n",
    "            if len(df_bf_slice.index)!=1 and len(homeLast)>2:\n",
    "                df_bf_slice=slice_df(df_bf_day, row.country, homeLast, row.awayTeamShortLow, type='10')\n",
    "        if len(df_bf_slice.index)!=1 and ' ' in row.awayTeamShortLow:\n",
    "            awayFirst=away_parts[0]\n",
    "            awayLast=away_parts[-1]\n",
    "            if len(df_bf_slice.index)!=1 and len(awayFirst)>2:\n",
    "                df_bf_slice=slice_df(df_bf_day, row.country, row.homeTeamShortLow, awayFirst, type='01')\n",
    "            if len(df_bf_slice.index)!=1 and len(awayLast)>2:\n",
    "                df_bf_slice=slice_df(df_bf_day, row.country, row.homeTeamShortLow, awayLast, type='01')\n",
    "            if len(df_bf_slice.index)!=1 and ' ' in row.homeTeamShortLow:\n",
    "                homeFirst=home_parts[0]\n",
    "                homeLast=home_parts[-1]\n",
    "                if len(df_bf_slice.index)!=1 and len(homeFirst)>2 and len(awayFirst)>2:\n",
    "                    df_bf_slice=slice_df(df_bf_day, row.country, homeFirst, awayFirst, type='11')\n",
    "                if len(df_bf_slice.index)!=1 and len(homeFirst)>2 and len(awayLast)>2:\n",
    "                    df_bf_slice=slice_df(df_bf_day, row.country, homeFirst, awayLast, type='11')\n",
    "                if len(df_bf_slice.index)!=1 and len(awayLast)>2 and len(awayFirst)>2:\n",
    "                    df_bf_slice=slice_df(df_bf_day, row.country, homeLast, awayFirst, type='11')\n",
    "                if len(df_bf_slice.index)!=1 and len(homeLast)>2 and len(awayLast)>2:\n",
    "                    df_bf_slice=slice_df(df_bf_day, row.country, homeLast, awayLast, type='11')\n",
    "        if len(df_bf_slice.index)==1:\n",
    "            eventId,home_id,away_id,bf_ht,bf_at=df_bf_slice.iloc[0][['eventId','home_id','away_id','home_name','away_name']]\n",
    "            print(f'found: {row.homeTeamShort}/{bf_ht} - {row.awayTeamShort}/{bf_at}')\n",
    "            binds.append({\n",
    "                'bf_home_name':bf_ht,\n",
    "                'bf_away_name':bf_at,\n",
    "                'bf_home_id':home_id,\n",
    "                'bf_away_id':away_id,\n",
    "                'bf_eventId':eventId,\n",
    "                'ss_home':row.homeTeamShort,\n",
    "                'ss_away':row.awayTeamShort,\n",
    "                'ss_id':row.id\n",
    "            })\n",
    "    #\n",
    "    d+=timedelta(days=1)\n",
    "    #break\n",
    "pd.DataFrame(binds).to_csv('data/binds.csv', index=False)"
   ]
  },
  {
   "source": [
    "## SS - Fbref"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bind_full(df_source,df_target, ds,de,target,cols, isWide=False):\n",
    "    binds=[]\n",
    "    d= ds\n",
    "    while d<de:\n",
    "        #print(d)\n",
    "        dloc=pytz.timezone(local_tz).localize(d)\n",
    "        ds_src=dloc-timedelta(days=1) if isWide else dloc\n",
    "        de_src=dloc+timedelta(days=2) if isWide else dloc+timedelta(days=2)\n",
    "        ds_tgt=d-timedelta(days=1) if isWide else d\n",
    "        de_tgt=d+timedelta(days=2) if isWide else d+timedelta(days=2)\n",
    "\n",
    "        df_src=df_source[(df_source['ts']>=ds_src) & (df_source['ts']<de_src)]\n",
    "        df_tgt=df_target[(df_target['ts']>=ds_tgt) & (df_target['ts']<de_tgt)]\n",
    "        for row in df_src.itertuples(index=False):\n",
    "            home_parts=row.homeTeamShortLow.split(' ')\n",
    "            away_parts=row.awayTeamShortLow.split(' ')\n",
    "            df_tgt_slice=slice_df(df_tgt, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='00')\n",
    "            if len(df_tgt_slice.index)!=1:\n",
    "                df_tgt_slice=slice_df(df_tgt, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='10')\n",
    "            if len(df_tgt_slice.index)!=1:\n",
    "                df_tgt_slice=slice_df(df_tgt, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='01')\n",
    "            if len(df_tgt_slice.index)!=1:\n",
    "                df_tgt_slice=slice_df(df_tgt, row.country, row.homeTeamShortLow, row.awayTeamShortLow, type='11')\n",
    "            if len(df_tgt_slice.index)!=1 and ' ' in row.homeTeamShortLow:\n",
    "                homeFirst=home_parts[0]\n",
    "                homeLast=home_parts[-1]\n",
    "                if len(homeFirst)>2:\n",
    "                    df_tgt_slice=slice_df(df_tgt, row.country, homeFirst, row.awayTeamShortLow, type='10')\n",
    "                if len(df_tgt_slice.index)!=1 and len(homeLast)>2:\n",
    "                    df_tgt_slice=slice_df(df_tgt, row.country, homeLast, row.awayTeamShortLow, type='10')\n",
    "            if len(df_tgt_slice.index)!=1 and ' ' in row.awayTeamShortLow:\n",
    "                awayFirst=away_parts[0]\n",
    "                awayLast=away_parts[-1]\n",
    "                if len(df_tgt_slice.index)!=1 and len(awayFirst)>2:\n",
    "                    df_tgt_slice=slice_df(df_tgt, row.country, row.homeTeamShortLow, awayFirst, type='01')\n",
    "                if len(df_tgt_slice.index)!=1 and len(awayLast)>2:\n",
    "                    df_tgt_slice=slice_df(df_tgt, row.country, row.homeTeamShortLow, awayLast, type='01')\n",
    "                if len(df_tgt_slice.index)!=1 and ' ' in row.homeTeamShortLow:\n",
    "                    homeFirst=home_parts[0]\n",
    "                    homeLast=home_parts[-1]\n",
    "                    if len(df_tgt_slice.index)!=1 and len(homeFirst)>2 and len(awayFirst)>2:\n",
    "                        df_tgt_slice=slice_df(df_tgt, row.country, homeFirst, awayFirst, type='11')\n",
    "                    if len(df_tgt_slice.index)!=1 and len(homeFirst)>2 and len(awayLast)>2:\n",
    "                        df_tgt_slice=slice_df(df_tgt, row.country, homeFirst, awayLast, type='11')\n",
    "                    if len(df_tgt_slice.index)!=1 and len(awayLast)>2 and len(awayFirst)>2:\n",
    "                        df_tgt_slice=slice_df(df_tgt, row.country, homeLast, awayFirst, type='11')\n",
    "                    if len(df_tgt_slice.index)!=1 and len(homeLast)>2 and len(awayLast)>2:\n",
    "                        df_tgt_slice=slice_df(df_tgt, row.country, homeLast, awayLast, type='11')\n",
    "            if len(df_tgt_slice.index)==1:\n",
    "                if len(cols)==3:\n",
    "                    mid,home_team,away_team=df_tgt_slice.iloc[0][cols]\n",
    "                else:\n",
    "                    mid,home_id,away_id,home_team,away_team=df_tgt_slice.iloc[0][cols]\n",
    "\n",
    "                #print(f'found: {row.homeTeamShort}/{home_team} - {row.awayTeamShort}/{away_team}')\n",
    "                binds.append({\n",
    "                    'target_home_name':home_team,\n",
    "                    'target_away_name':away_team,\n",
    "                    'target_home_id':home_id if len(cols)>3 else home_team,\n",
    "                    'target_away_id':away_id if len(cols)>3 else away_team,\n",
    "                    'target_mid':mid,\n",
    "                    'ss_home':row.homeTeamShort,\n",
    "                    'ss_away':row.awayTeamShort,\n",
    "                    'ss_id':row.id\n",
    "                })\n",
    "        #\n",
    "        d+=timedelta(days=1)\n",
    "    df_binds=pd.DataFrame(binds)\n",
    "    df_binds.to_csv(f'data/binds_ss_{target}.csv', index=False)\n",
    "    return df_binds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_fbref' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a93fb2ea3ee0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_binds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbind_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_fbref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2015\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fbref'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tid1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tid2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'team1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'team2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_fbref' is not defined"
     ]
    }
   ],
   "source": [
    "df_binds=bind_full(df_ss,df_fbref, datetime(2015, 1, 1), datetime(2020, 12, 1),'fbref',['mid','tid1','tid2','team1','team2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_semi_none(df_binds, df_ss, ds):\n",
    "    df_binds.loc[df_binds['target_home_id'].isna(),'target_home_id']=''\n",
    "    df_binds.loc[df_binds['target_away_id'].isna(),'target_away_id']=''\n",
    "    ds = pytz.timezone(local_tz).localize(ds)\n",
    "    ss=df_ss.loc[df_ss['ts']>=ds]\n",
    "\n",
    "    #df_binds=pd.read_csv('data/binds.csv', index_col=None)\n",
    "\n",
    "    df_ss_binded=ss.merge(df_binds, left_on=['id','homeTeamShort', 'awayTeamShort'] , right_on=['ss_id','ss_home','ss_away'], how='inner')\n",
    "    df_ss_binded=df_ss_binded.drop_duplicates()\n",
    "    df_semi = ss.loc[~(ss['id'].isin(df_ss_binded['id']))]\n",
    "    df_semi=df_semi.merge(df_binds[['target_home_name', 'target_home_id', 'ss_home']].drop_duplicates(), left_on=['homeTeamShort'] , right_on=['ss_home'], how='left')\n",
    "    df_semi=df_semi.merge(df_binds[['target_away_name', 'target_away_id', 'ss_away']].drop_duplicates(), left_on=['awayTeamShort'] , right_on=['ss_away'], how='left')\n",
    "    df_not=df_semi.loc[(df_semi['target_home_id'].isna()) & (df_semi['target_away_id'].isna())]\n",
    "    df_semi = df_semi.loc[~(df_semi['id'].isin(df_not['id']))]\n",
    "    df_semi=df_semi.drop_duplicates()\n",
    "    df_semi.loc[df_semi['target_home_id'].isna(),'target_home_id']=''\n",
    "    df_semi.loc[df_semi['target_away_id'].isna(),'target_away_id']=''\n",
    "    print(' full: {}, semi: {}, non: {}'.format(len(df_ss_binded.index),len(df_semi.index),len(df_not.index)) )\n",
    "    return df_ss_binded,df_semi,df_not\n",
    "\n",
    "def bind_semi(df_semi,df_target,cols, isWide=False):\n",
    "    binds=[]\n",
    "    binded_total=0\n",
    "    for row in df_semi.itertuples(index=False):\n",
    "        d=row.ts.replace(tzinfo=None)\n",
    "        ds_tgt=d-timedelta(days=1) if isWide else d\n",
    "        de_tgt=d+timedelta(days=2) if isWide else d+timedelta(days=2)\n",
    "        if row.target_home_id!='':\n",
    "            #print(0,row.target_home_id)\n",
    "            \n",
    "            df_target_slice=df_target[(df_target['ts']>=ds_tgt) & (df_target['ts']<de_tgt) & (df_target[cols[1]]==row.target_home_id)]\n",
    "            if len(df_target_slice.index)==1:\n",
    "                ssid, sshid, sshname, ssaname = (row.id,row.target_home_id,row.homeTeamShort,row.awayTeamShort)\n",
    "                target_id, target_hid, target_aid, target_hname, target_aname = (df_target_slice.iloc[0][cols]).values\n",
    "                #print('Found on home id={}, teams: {}/{} vs {}/{}, match ids {}-{}'.format(sshid, sshname,target_hname,ssaname,target_aname,ssid,target_id ))\n",
    "                binds.append({\n",
    "                    'target_home_name':target_hname,\n",
    "                    'target_away_name':target_aname,\n",
    "                    'target_home_id':target_hid,\n",
    "                    'target_away_id':target_aid,\n",
    "                    'target_mid':target_id,\n",
    "                    'ss_home':sshname,\n",
    "                    'ss_away':ssaname,\n",
    "                    'ss_id':ssid\n",
    "                })\n",
    "                binded_total+=1\n",
    "        else:\n",
    "            #print(1,row.target_away_id)\n",
    "            df_target_slice=df_target[(df_target['ts']>=ds_tgt) & (df_target['ts']<de_tgt) & (df_target[cols[2]]==row.target_away_id)]\n",
    "            if len(df_target_slice.index)==1:\n",
    "                ssid, ssaid, sshname, ssaname = (row.id,row.target_away_id,row.homeTeamShort,row.awayTeamShort)\n",
    "                target_id, target_hid, target_aid, target_hname, target_aname = (df_target_slice.iloc[0][cols]).values\n",
    "                #print('Found on away id={}, teams: {}/{} vs {}/{}, match ids {}-{}'.format(ssaid, sshname,target_hname,ssaname,target_aname,ssid,target_id ))\n",
    "                binds.append({\n",
    "                    'target_home_name':target_hname,\n",
    "                    'target_away_name':target_aname,\n",
    "                    'target_home_id':target_hid,\n",
    "                    'target_away_id':target_aid,\n",
    "                    'target_mid':target_id,\n",
    "                    'ss_home':sshname,\n",
    "                    'ss_away':ssaname,\n",
    "                    'ss_id':ssid\n",
    "                })\n",
    "                binded_total+=1\n",
    "    print (f'Done! {binded_total} matches binded')\n",
    "    return pd.DataFrame(binds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#df_binds=pd.read_csv('data/binds_ss_fbref.csv', index_col=None)\n",
    "df_ss_binded,df_semi,df_not=full_semi_none(df_binds, df_ss, datetime(2015, 1, 1))\n",
    "df_binds_from_semi=bind_semi(df_semi,df_fbref,['mid','tid1','tid2','team1','team2'])\n",
    "df_binds=pd.concat([df_binds,df_binds_from_semi], axis=0).drop_duplicates(subset=['ss_id','target_mid'])\n",
    "df_binds.to_csv('data/binds_ss_fbref.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df_binds_from_semi=bind_semi(df_semi,df_fbref,['mid','tid1','tid2','team1','team2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binds_from_semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_binds,df_binds_from_semi], axis=0).drop_duplicates(subset=['ss_id','target_mid'])"
   ]
  },
  {
   "source": [
    "## SS - OP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**********  Narrow approach  **********\n",
      " full: 28339, semi: 38317, non: 12080\n",
      "**********  Wide approach  **********\n",
      " full: 28347, semi: 39046, non: 12080\n"
     ]
    }
   ],
   "source": [
    "df_binds=bind_full(df_ss,df_op, datetime(2015, 1, 1), datetime(2020, 12, 1),'op',['link','t1','t2'])\n",
    "print('*'*10,' Narrow approach ','*'*10)\n",
    "df_ss_binded,df_semi,df_not=full_semi_none(df_binds, df_ss, datetime(2015, 1, 1))\n",
    "df_binds1=bind_full(pd.concat([df_semi,df_not],axis=0).drop_duplicates(subset=['id']),df_op, datetime(2015, 1, 1), datetime(2020, 12, 1),'op',['link','t1','t2'], isWide=True)\n",
    "df_binds=pd.concat([df_binds,df_binds1],axis=0)\n",
    "print('*'*10,' Wide approach ','*'*10)\n",
    "df_ss_binded,df_semi,df_not=full_semi_none(df_binds, df_ss, datetime(2015, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  awayTeam  homeScoreHT          homeTeam  \\\n",
       "0      Queens Park Rangers          2.0           Burnley   \n",
       "1      Queens Park Rangers          2.0           Burnley   \n",
       "2         Newcastle United          1.0           Chelsea   \n",
       "3          Manchester City          0.0           Everton   \n",
       "4          Manchester City          0.0           Everton   \n",
       "...                    ...          ...               ...   \n",
       "50392       Trelleborgs FF          0.0  Jönköpings Södra   \n",
       "50393          Västerås SK          0.0              Umeå   \n",
       "50394        Ljungskile SK          0.0         Östers IF   \n",
       "50395      Vorskla Poltava          2.0       Dynamo Kyiv   \n",
       "50396     Shakhtar Donetsk          0.0       SK Dnipro-1   \n",
       "\n",
       "                             ts  awayScoreFT  status  winnerCode  country  \\\n",
       "0     2015-01-10 15:00:00+00:00          1.0   100.0         1.0  england   \n",
       "1     2015-01-10 15:00:00+00:00          1.0   100.0         1.0  england   \n",
       "2     2015-01-10 15:00:00+00:00          0.0   100.0         1.0  england   \n",
       "3     2015-01-10 15:00:00+00:00          1.0   100.0         3.0  england   \n",
       "4     2015-01-10 15:00:00+00:00          1.0   100.0         3.0  england   \n",
       "...                         ...          ...     ...         ...      ...   \n",
       "50392 2020-11-28 14:00:00+00:00          1.0   100.0         1.0   sweden   \n",
       "50393 2020-11-28 14:00:00+00:00          0.0   100.0         3.0   sweden   \n",
       "50394 2020-11-28 14:00:00+00:00          1.0   100.0         2.0   sweden   \n",
       "50395 2020-11-28 15:00:00+00:00          0.0   100.0         1.0  ukraine   \n",
       "50396 2020-11-28 17:30:00+00:00          1.0   100.0         2.0  ukraine   \n",
       "\n",
       "       done awayTeamShort  ...  awayScoreET  countryCode homeTeamShortLow  \\\n",
       "0         1           QPR  ...          1.0           GB          burnley   \n",
       "1         1           QPR  ...          1.0           GB          burnley   \n",
       "2         1     Newcastle  ...          0.0           GB          chelsea   \n",
       "3         1      Man City  ...          1.0           GB          everton   \n",
       "4         1      Man City  ...          1.0           GB          everton   \n",
       "...     ...           ...  ...          ...          ...              ...   \n",
       "50392     1    Trelleborg  ...          1.0           SE           jsodra   \n",
       "50393     1      Västerås  ...          0.0           SE             umea   \n",
       "50394     1    Ljungskile  ...          1.0           SE            oster   \n",
       "50395     1       Vorskla  ...          0.0           UA      dynamo kyiv   \n",
       "50396     1   Shakhtar D.  ...          1.0           UA       sk dnipro1   \n",
       "\n",
       "      awayTeamShortLow  target_home_name  target_home_id      ss_home  \\\n",
       "0                  qpr           Burnley         Burnley      Burnley   \n",
       "1                  qpr       Burnley U23     Burnley U23      Burnley   \n",
       "2            newcastle           Chelsea         Chelsea      Chelsea   \n",
       "3             man city           Everton         Everton      Everton   \n",
       "4             man city           Everton         Everton      Everton   \n",
       "...                ...               ...             ...          ...   \n",
       "50392       trelleborg               NaN                          NaN   \n",
       "50393         vasteras           Umea FC         Umea FC         Umeå   \n",
       "50394       ljungskile            Osters          Osters        Öster   \n",
       "50395          vorskla         Dyn. Kyiv       Dyn. Kyiv  Dynamo Kyiv   \n",
       "50396       shakhtar d          Dnipro-1        Dnipro-1  SK Dnipro-1   \n",
       "\n",
       "       target_away_name    target_away_id      ss_away  \n",
       "0                   QPR               QPR          QPR  \n",
       "1                   QPR               QPR          QPR  \n",
       "2             Newcastle         Newcastle    Newcastle  \n",
       "3       Manchester City   Manchester City     Man City  \n",
       "4        Stoke City U23    Stoke City U23     Man City  \n",
       "...                 ...               ...          ...  \n",
       "50392       Trelleborgs       Trelleborgs   Trelleborg  \n",
       "50393       Vasteras SK       Vasteras SK     Västerås  \n",
       "50394        Ljungskile        Ljungskile   Ljungskile  \n",
       "50395   Vorskla Poltava   Vorskla Poltava      Vorskla  \n",
       "50396  Shakhtar Donetsk  Shakhtar Donetsk  Shakhtar D.  \n",
       "\n",
       "[38317 rows x 29 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>awayTeam</th>\n      <th>homeScoreHT</th>\n      <th>homeTeam</th>\n      <th>ts</th>\n      <th>awayScoreFT</th>\n      <th>status</th>\n      <th>winnerCode</th>\n      <th>country</th>\n      <th>done</th>\n      <th>awayTeamShort</th>\n      <th>...</th>\n      <th>awayScoreET</th>\n      <th>countryCode</th>\n      <th>homeTeamShortLow</th>\n      <th>awayTeamShortLow</th>\n      <th>target_home_name</th>\n      <th>target_home_id</th>\n      <th>ss_home</th>\n      <th>target_away_name</th>\n      <th>target_away_id</th>\n      <th>ss_away</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Queens Park Rangers</td>\n      <td>2.0</td>\n      <td>Burnley</td>\n      <td>2015-01-10 15:00:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>england</td>\n      <td>1</td>\n      <td>QPR</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>GB</td>\n      <td>burnley</td>\n      <td>qpr</td>\n      <td>Burnley</td>\n      <td>Burnley</td>\n      <td>Burnley</td>\n      <td>QPR</td>\n      <td>QPR</td>\n      <td>QPR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Queens Park Rangers</td>\n      <td>2.0</td>\n      <td>Burnley</td>\n      <td>2015-01-10 15:00:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>england</td>\n      <td>1</td>\n      <td>QPR</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>GB</td>\n      <td>burnley</td>\n      <td>qpr</td>\n      <td>Burnley U23</td>\n      <td>Burnley U23</td>\n      <td>Burnley</td>\n      <td>QPR</td>\n      <td>QPR</td>\n      <td>QPR</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Newcastle United</td>\n      <td>1.0</td>\n      <td>Chelsea</td>\n      <td>2015-01-10 15:00:00+00:00</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>england</td>\n      <td>1</td>\n      <td>Newcastle</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>GB</td>\n      <td>chelsea</td>\n      <td>newcastle</td>\n      <td>Chelsea</td>\n      <td>Chelsea</td>\n      <td>Chelsea</td>\n      <td>Newcastle</td>\n      <td>Newcastle</td>\n      <td>Newcastle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Manchester City</td>\n      <td>0.0</td>\n      <td>Everton</td>\n      <td>2015-01-10 15:00:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>3.0</td>\n      <td>england</td>\n      <td>1</td>\n      <td>Man City</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>GB</td>\n      <td>everton</td>\n      <td>man city</td>\n      <td>Everton</td>\n      <td>Everton</td>\n      <td>Everton</td>\n      <td>Manchester City</td>\n      <td>Manchester City</td>\n      <td>Man City</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Manchester City</td>\n      <td>0.0</td>\n      <td>Everton</td>\n      <td>2015-01-10 15:00:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>3.0</td>\n      <td>england</td>\n      <td>1</td>\n      <td>Man City</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>GB</td>\n      <td>everton</td>\n      <td>man city</td>\n      <td>Everton</td>\n      <td>Everton</td>\n      <td>Everton</td>\n      <td>Stoke City U23</td>\n      <td>Stoke City U23</td>\n      <td>Man City</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50392</th>\n      <td>Trelleborgs FF</td>\n      <td>0.0</td>\n      <td>Jönköpings Södra</td>\n      <td>2020-11-28 14:00:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>sweden</td>\n      <td>1</td>\n      <td>Trelleborg</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>SE</td>\n      <td>jsodra</td>\n      <td>trelleborg</td>\n      <td>NaN</td>\n      <td></td>\n      <td>NaN</td>\n      <td>Trelleborgs</td>\n      <td>Trelleborgs</td>\n      <td>Trelleborg</td>\n    </tr>\n    <tr>\n      <th>50393</th>\n      <td>Västerås SK</td>\n      <td>0.0</td>\n      <td>Umeå</td>\n      <td>2020-11-28 14:00:00+00:00</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>3.0</td>\n      <td>sweden</td>\n      <td>1</td>\n      <td>Västerås</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>SE</td>\n      <td>umea</td>\n      <td>vasteras</td>\n      <td>Umea FC</td>\n      <td>Umea FC</td>\n      <td>Umeå</td>\n      <td>Vasteras SK</td>\n      <td>Vasteras SK</td>\n      <td>Västerås</td>\n    </tr>\n    <tr>\n      <th>50394</th>\n      <td>Ljungskile SK</td>\n      <td>0.0</td>\n      <td>Östers IF</td>\n      <td>2020-11-28 14:00:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>2.0</td>\n      <td>sweden</td>\n      <td>1</td>\n      <td>Ljungskile</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>SE</td>\n      <td>oster</td>\n      <td>ljungskile</td>\n      <td>Osters</td>\n      <td>Osters</td>\n      <td>Öster</td>\n      <td>Ljungskile</td>\n      <td>Ljungskile</td>\n      <td>Ljungskile</td>\n    </tr>\n    <tr>\n      <th>50395</th>\n      <td>Vorskla Poltava</td>\n      <td>2.0</td>\n      <td>Dynamo Kyiv</td>\n      <td>2020-11-28 15:00:00+00:00</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>ukraine</td>\n      <td>1</td>\n      <td>Vorskla</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>UA</td>\n      <td>dynamo kyiv</td>\n      <td>vorskla</td>\n      <td>Dyn. Kyiv</td>\n      <td>Dyn. Kyiv</td>\n      <td>Dynamo Kyiv</td>\n      <td>Vorskla Poltava</td>\n      <td>Vorskla Poltava</td>\n      <td>Vorskla</td>\n    </tr>\n    <tr>\n      <th>50396</th>\n      <td>Shakhtar Donetsk</td>\n      <td>0.0</td>\n      <td>SK Dnipro-1</td>\n      <td>2020-11-28 17:30:00+00:00</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>2.0</td>\n      <td>ukraine</td>\n      <td>1</td>\n      <td>Shakhtar D.</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>UA</td>\n      <td>sk dnipro1</td>\n      <td>shakhtar d</td>\n      <td>Dnipro-1</td>\n      <td>Dnipro-1</td>\n      <td>SK Dnipro-1</td>\n      <td>Shakhtar Donetsk</td>\n      <td>Shakhtar Donetsk</td>\n      <td>Shakhtar D.</td>\n    </tr>\n  </tbody>\n</table>\n<p>38317 rows × 29 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "df_semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done! 5938 matches binded\n",
      " full: 34082, semi: 51263, non: 7560\n",
      "Done! 960 matches binded\n",
      " full: 34738, semi: 80449, non: 6440\n"
     ]
    }
   ],
   "source": [
    "df_binds_from_semi=bind_semi(df_semi,df_op,['link','t1','t2','t1','t2'])\n",
    "df_binds=pd.concat([df_binds,df_binds_from_semi], axis=0).drop_duplicates(subset=['ss_id','target_mid'])\n",
    "df_binds.to_csv('data/binds_ss_op1.csv', index=False)\n",
    "\n",
    "df_ss_binded,df_semi,df_not=full_semi_none(df_binds, df_ss, datetime(2015, 1, 1))\n",
    "df_binds_from_semi=bind_semi(df_semi,df_op,['link','t1','t2','t1','t2'],isWide=True)\n",
    "df_binds=pd.concat([df_binds,df_binds_from_semi], axis=0).drop_duplicates(subset=['ss_id','target_mid'])\n",
    "df_binds.to_csv('data/binds_ss_op2.csv', index=False)\n",
    "\n",
    "df_ss_binded,df_semi,df_not=full_semi_none(df_binds, df_ss, datetime(2015, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    ds    country                               liga  \\\n",
       "0       19/02/16 15:00    england          national-league-2018-2019   \n",
       "1       14/03/25 19:00    germany               bundesliga-2013-2014   \n",
       "2       16/07/14 00:45    ecuador                       serie-a-2016   \n",
       "3       17/04/08 14:00    england               league-two-2016-2017   \n",
       "4       16/09/20 15:00       iran  persian-gulf-pro-league-2016-2017   \n",
       "...                ...        ...                                ...   \n",
       "145372  18/12/01 14:30    germany               bundesliga-2018-2019   \n",
       "145373  19/12/08 16:30    croatia                    1-hnl-2019-2020   \n",
       "145374  16/08/14 20:30       peru              primera-division-2016   \n",
       "145375  10/11/20 15:00    england               league-one-2010-2011   \n",
       "145376  14/10/15 21:10  argentina              primera-division-2014   \n",
       "\n",
       "           season              t1                   t2  sc1  sc2 odds1  \\\n",
       "0       2018/2019    Boreham Wood           Hartlepool    0    4  2.29   \n",
       "1       2013/2014        Dortmund              Schalke    0    0  1.46   \n",
       "2            2016    Barcelona SC       Guayaquil City    2    0  1.31   \n",
       "3       2016/2017   Cambridge Utd        Leyton Orient    3    0  1.42   \n",
       "4       2016/2017  Esteghlal F.C.             Zob Ahan    2    1   1.9   \n",
       "...           ...             ...                  ...  ...  ...   ...   \n",
       "145372  2018/2019       Stuttgart             Augsburg    1    0  2.66   \n",
       "145373  2019/2020          Rijeka           Istra 1961    2    0  1.22   \n",
       "145374       2016    Alianza Lima  Comerciantes Unidos    0    0  1.51   \n",
       "145375  2010/2011        Brighton       Bristol Rovers    2    2  1.45   \n",
       "145376       2014      Godoy Cruz                Tigre    4    3  2.16   \n",
       "\n",
       "        oddsdraw  odds2  bn  \\\n",
       "0           3.26   3.09  12   \n",
       "1           4.82   6.42   7   \n",
       "2           5.15   8.16   9   \n",
       "3           4.53    7.6  11   \n",
       "4           2.94   4.59   9   \n",
       "...          ...    ...  ..   \n",
       "145372      3.39   2.71  12   \n",
       "145373      5.89  12.67  14   \n",
       "145374      3.92   6.05   9   \n",
       "145375      4.34   6.56   6   \n",
       "145376      3.17    3.5   8   \n",
       "\n",
       "                                                     link  done  \\\n",
       "0       /soccer/england/national-league-2018-2019/bore...     1   \n",
       "1       /soccer/germany/bundesliga-2013-2014/dortmund-...     1   \n",
       "2       /soccer/ecuador/serie-a-2016/barcelona-sc-guay...     1   \n",
       "3       /soccer/england/league-two-2016-2017/cambridge...     1   \n",
       "4       /soccer/iran/persian-gulf-pro-league-2016-2017...     1   \n",
       "...                                                   ...   ...   \n",
       "145372  /soccer/germany/bundesliga-2018-2019/vfb-stutt...     0   \n",
       "145373  /soccer/croatia/1-hnl-2019-2020/rijeka-istra-1...     0   \n",
       "145374  /soccer/peru/primera-division-2016/a-lima-come...     0   \n",
       "145375  /soccer/england/league-one-2010-2011/brighton-...     0   \n",
       "145376  /soccer/argentina/primera-division-2014/godoy-...     0   \n",
       "\n",
       "        home_name_low        away_name_low                  ts  \n",
       "0        boreham wood           hartlepool 2019-02-16 15:00:00  \n",
       "1            dortmund              schalke 2014-03-25 19:00:00  \n",
       "2        barcelona sc       guayaquil city 2016-07-14 00:45:00  \n",
       "3       cambridge utd        leyton orient 2017-04-08 14:00:00  \n",
       "4        esteghlal fc             zob ahan 2016-09-20 15:00:00  \n",
       "...               ...                  ...                 ...  \n",
       "145372      stuttgart             augsburg 2018-12-01 14:30:00  \n",
       "145373         rijeka           istra 1961 2019-12-08 16:30:00  \n",
       "145374   alianza lima  comerciantes unidos 2016-08-14 20:30:00  \n",
       "145375       brighton       bristol rovers 2010-11-20 15:00:00  \n",
       "145376     godoy cruz                tigre 2014-10-15 21:10:00  \n",
       "\n",
       "[145377 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>country</th>\n      <th>liga</th>\n      <th>season</th>\n      <th>t1</th>\n      <th>t2</th>\n      <th>sc1</th>\n      <th>sc2</th>\n      <th>odds1</th>\n      <th>oddsdraw</th>\n      <th>odds2</th>\n      <th>bn</th>\n      <th>link</th>\n      <th>done</th>\n      <th>home_name_low</th>\n      <th>away_name_low</th>\n      <th>ts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19/02/16 15:00</td>\n      <td>england</td>\n      <td>national-league-2018-2019</td>\n      <td>2018/2019</td>\n      <td>Boreham Wood</td>\n      <td>Hartlepool</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2.29</td>\n      <td>3.26</td>\n      <td>3.09</td>\n      <td>12</td>\n      <td>/soccer/england/national-league-2018-2019/bore...</td>\n      <td>1</td>\n      <td>boreham wood</td>\n      <td>hartlepool</td>\n      <td>2019-02-16 15:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14/03/25 19:00</td>\n      <td>germany</td>\n      <td>bundesliga-2013-2014</td>\n      <td>2013/2014</td>\n      <td>Dortmund</td>\n      <td>Schalke</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.46</td>\n      <td>4.82</td>\n      <td>6.42</td>\n      <td>7</td>\n      <td>/soccer/germany/bundesliga-2013-2014/dortmund-...</td>\n      <td>1</td>\n      <td>dortmund</td>\n      <td>schalke</td>\n      <td>2014-03-25 19:00:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16/07/14 00:45</td>\n      <td>ecuador</td>\n      <td>serie-a-2016</td>\n      <td>2016</td>\n      <td>Barcelona SC</td>\n      <td>Guayaquil City</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.31</td>\n      <td>5.15</td>\n      <td>8.16</td>\n      <td>9</td>\n      <td>/soccer/ecuador/serie-a-2016/barcelona-sc-guay...</td>\n      <td>1</td>\n      <td>barcelona sc</td>\n      <td>guayaquil city</td>\n      <td>2016-07-14 00:45:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17/04/08 14:00</td>\n      <td>england</td>\n      <td>league-two-2016-2017</td>\n      <td>2016/2017</td>\n      <td>Cambridge Utd</td>\n      <td>Leyton Orient</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1.42</td>\n      <td>4.53</td>\n      <td>7.6</td>\n      <td>11</td>\n      <td>/soccer/england/league-two-2016-2017/cambridge...</td>\n      <td>1</td>\n      <td>cambridge utd</td>\n      <td>leyton orient</td>\n      <td>2017-04-08 14:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16/09/20 15:00</td>\n      <td>iran</td>\n      <td>persian-gulf-pro-league-2016-2017</td>\n      <td>2016/2017</td>\n      <td>Esteghlal F.C.</td>\n      <td>Zob Ahan</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.9</td>\n      <td>2.94</td>\n      <td>4.59</td>\n      <td>9</td>\n      <td>/soccer/iran/persian-gulf-pro-league-2016-2017...</td>\n      <td>1</td>\n      <td>esteghlal fc</td>\n      <td>zob ahan</td>\n      <td>2016-09-20 15:00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145372</th>\n      <td>18/12/01 14:30</td>\n      <td>germany</td>\n      <td>bundesliga-2018-2019</td>\n      <td>2018/2019</td>\n      <td>Stuttgart</td>\n      <td>Augsburg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.66</td>\n      <td>3.39</td>\n      <td>2.71</td>\n      <td>12</td>\n      <td>/soccer/germany/bundesliga-2018-2019/vfb-stutt...</td>\n      <td>0</td>\n      <td>stuttgart</td>\n      <td>augsburg</td>\n      <td>2018-12-01 14:30:00</td>\n    </tr>\n    <tr>\n      <th>145373</th>\n      <td>19/12/08 16:30</td>\n      <td>croatia</td>\n      <td>1-hnl-2019-2020</td>\n      <td>2019/2020</td>\n      <td>Rijeka</td>\n      <td>Istra 1961</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.22</td>\n      <td>5.89</td>\n      <td>12.67</td>\n      <td>14</td>\n      <td>/soccer/croatia/1-hnl-2019-2020/rijeka-istra-1...</td>\n      <td>0</td>\n      <td>rijeka</td>\n      <td>istra 1961</td>\n      <td>2019-12-08 16:30:00</td>\n    </tr>\n    <tr>\n      <th>145374</th>\n      <td>16/08/14 20:30</td>\n      <td>peru</td>\n      <td>primera-division-2016</td>\n      <td>2016</td>\n      <td>Alianza Lima</td>\n      <td>Comerciantes Unidos</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.51</td>\n      <td>3.92</td>\n      <td>6.05</td>\n      <td>9</td>\n      <td>/soccer/peru/primera-division-2016/a-lima-come...</td>\n      <td>0</td>\n      <td>alianza lima</td>\n      <td>comerciantes unidos</td>\n      <td>2016-08-14 20:30:00</td>\n    </tr>\n    <tr>\n      <th>145375</th>\n      <td>10/11/20 15:00</td>\n      <td>england</td>\n      <td>league-one-2010-2011</td>\n      <td>2010/2011</td>\n      <td>Brighton</td>\n      <td>Bristol Rovers</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.45</td>\n      <td>4.34</td>\n      <td>6.56</td>\n      <td>6</td>\n      <td>/soccer/england/league-one-2010-2011/brighton-...</td>\n      <td>0</td>\n      <td>brighton</td>\n      <td>bristol rovers</td>\n      <td>2010-11-20 15:00:00</td>\n    </tr>\n    <tr>\n      <th>145376</th>\n      <td>14/10/15 21:10</td>\n      <td>argentina</td>\n      <td>primera-division-2014</td>\n      <td>2014</td>\n      <td>Godoy Cruz</td>\n      <td>Tigre</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2.16</td>\n      <td>3.17</td>\n      <td>3.5</td>\n      <td>8</td>\n      <td>/soccer/argentina/primera-division-2014/godoy-...</td>\n      <td>0</td>\n      <td>godoy cruz</td>\n      <td>tigre</td>\n      <td>2014-10-15 21:10:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>145377 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df_op"
   ]
  },
  {
   "source": [
    "# Teams\n",
    "Extract teams with Unicode "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams=pd.read_csv('data/teams_names.csv', index_col=None)\n",
    "df_a=df_ss[['homeTeam','homeTeamShort','country','tournament']]\n",
    "df_a.columns=['Team','TeamShort','country','tournament']\n",
    "df_b=df_ss[['awayTeam','awayTeamShort','country','tournament']]\n",
    "df_b.columns=['Team','TeamShort','country','tournament']\n",
    "df_teams_new=pd.concat([df_a,df_b], axis=0).drop_duplicates()\n",
    "df_teams_new['TeamEn']=df_teams_new['Team'].replace(dicUnicode2En, regex=True)\n",
    "df_teams_new['TeamShortEn']=df_teams_new['TeamShort'].replace(dicUnicode2En, regex=True)\n",
    "df_teams_new=df_teams_new.loc[df_teams_new['Team'].str.contains(r'[^\\x00-\\x7F]+')]\n",
    "#df_teams_new['TeamEn']=''\n",
    "#df_teams_new['TeamShortEn']=''\n",
    "\n",
    "df_teams=pd.concat([df_teams,df_teams_new], axis=0).drop_duplicates(subset=['Team','country','tournament'], keep='first')\n",
    "\n",
    "#df_teams_new.to_csv('data/teams_names1.csv', index=False)\n",
    "df_teams.to_csv('data/teams_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams"
   ]
  },
  {
   "source": [
    "## Make binded SS list\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pytz.timezone(local_tz).localize(datetime(2015, 5, 1))\n",
    "ss=df_ss.loc[df_ss['ts']>=ds]\n",
    "\n",
    "df_binds=pd.read_csv('data/binds.csv', index_col=None)\n",
    "df_binds = df_binds.loc[~((df_binds['bf_home_name'].str.contains('\\(Y\\)')) | (df_binds['bf_home_name'].str.contains(' U20')) | (df_binds['bf_away_name'].str.contains('\\(Y\\)')) | (df_binds['bf_away_name'].str.contains(' U20'))) ]\n",
    "\n",
    "df_ss_binded=ss.merge(df_binds, left_on=['id','homeTeamShort', 'awayTeamShort'] , right_on=['ss_id','ss_home','ss_away'], how='inner')\n",
    "df_ss_binded=df_ss_binded.drop_duplicates()\n",
    "df_semi = ss.loc[~(ss['id'].isin(df_ss_binded['id']))]\n",
    "\n",
    "df_semi=df_semi.merge(df_binds[['bf_home_name', 'bf_home_id', 'ss_home']].drop_duplicates(), left_on=['homeTeamShort'] , right_on=['ss_home'], how='left')\n",
    "df_semi=df_semi.merge(df_binds[['bf_away_name', 'bf_away_id', 'ss_away']].drop_duplicates(), left_on=['awayTeamShort'] , right_on=['ss_away'], how='left')\n",
    "df_not=df_semi.loc[(df_semi['bf_home_id'].isna()) & (df_semi['bf_away_id'].isna())]\n",
    "df_semi = df_semi.loc[~(df_semi['id'].isin(df_not['id']))]\n",
    "df_semi=df_semi.drop_duplicates()\n",
    "print(' full: {}, semi: {}, non: {}'.format(len(df_ss_binded.index),len(df_semi.index),len(df_not.index)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binds=[]\n",
    "binded_total=0\n",
    "for row in df_semi.itertuples(index=False):\n",
    "    d=row.ts.replace(tzinfo=None)\n",
    "    if row.bf_home_id>0:\n",
    "        #print(0,row.bf_home_id)\n",
    "        df_bf_slice=df_bf[(df_bf['inplayTime']>=d) & (df_bf['inplayTime']<d+timedelta(days=1)) & (df_bf['home_id']==row.bf_home_id)]\n",
    "        if len(df_bf_slice.index)==1:\n",
    "            ssid, sshid, sshname, ssaname = (row.id,row.bf_home_id,row.homeTeamShort,row.awayTeamShort)\n",
    "            bfid, bfhid, bfaid, bfhname, bfaname = (df_bf_slice.iloc[0][['eventId','home_id','away_id','home_name','away_name']]).values\n",
    "            print('Found on home id={}, teams: {}/{} vs {}/{}, match ids {}-{}'.format(sshid, sshname,bfhname,ssaname,bfaname,ssid,bfid ))\n",
    "            binds.append({\n",
    "                'bf_home_name':bfhname,\n",
    "                'bf_away_name':bfaname,\n",
    "                'bf_home_id':bfhid,\n",
    "                'bf_away_id':bfaid,\n",
    "                'bf_eventId':bfid,\n",
    "                'ss_home':sshname,\n",
    "                'ss_away':ssaname,\n",
    "                'ss_id':ssid\n",
    "            })\n",
    "            binded_total+=1\n",
    "    else:\n",
    "        #print(1,row.bf_away_id)\n",
    "        df_bf_slice=df_bf[(df_bf['inplayTime']>=d) & (df_bf['inplayTime']<d+timedelta(days=1)) & (df_bf['away_id']==row.bf_away_id)]\n",
    "        if len(df_bf_slice.index)==1:\n",
    "            ssid, ssaid, sshname, ssaname = (row.id,row.bf_away_id,row.homeTeamShort,row.awayTeamShort)\n",
    "            bfid, bfhid, bfaid, bfhname, bfaname = (df_bf_slice.iloc[0][['eventId','home_id','away_id','home_name','away_name']]).values\n",
    "            print('Found on away id={}, teams: {}/{} vs {}/{}, match ids {}-{}'.format(ssaid, sshname,bfhname,ssaname,bfaname,ssid,bfid ))\n",
    "            binds.append({\n",
    "                'bf_home_name':bfhname,\n",
    "                'bf_away_name':bfaname,\n",
    "                'bf_home_id':bfhid,\n",
    "                'bf_away_id':bfaid,\n",
    "                'bf_eventId':bfid,\n",
    "                'ss_home':sshname,\n",
    "                'ss_away':ssaname,\n",
    "                'ss_id':ssid\n",
    "            })\n",
    "            binded_total+=1\n",
    "print (f'Done! {binded_total} matches binded')\n",
    "pd.concat([df_binds,pd.DataFrame(binds)], axis=0).drop_duplicates(subset=['ss_id','bf_eventId']).to_csv('data/binds.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binds.drop_duplicates(subset=['ss_id','bf_eventId']).to_csv('data/binds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss_binded.drop_duplicates(subset=['ss_id','bf_eventId']).to_csv('data/matches_binded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df1,df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/matches_2015.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/matches_2015.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "for y in range(2015,2021):\n",
    "    for f in glob.glob(path.join('data/bf/days/', f'{y}*_matches.csv')):\n",
    "        print(f)\n",
    "        dfs.append(pd.read_csv(f))\n",
    "        \n",
    "df=pd.concat(dfs, axis=0)\n",
    "df=df.loc[~df['home_id'].isna()]\n",
    "df=df[['eventId','countryCode','openDate','eventName','home_id','home_name','away_id','away_name','draw_id','draw_name','inplayTime','halfTime']]\n",
    "df=df[df['eventName'].str.contains(' v ')]\n",
    "df[['ht','at']]=df.apply(lambda x: x.eventName.split(' v '), axis=1, result_type=\"expand\")\n",
    "df=df.reset_index(drop=True)\n",
    "df1=df.loc[(df['draw_name']!='The Draw')]\n",
    "df2=df.loc[(df['draw_name']=='The Draw')]\n",
    "df1.loc[(df1['away_name']=='The Draw') & (df1['ht'].str.lower()==df1['home_name'].str.lower()),'away_id']=df1['draw_id']\n",
    "df1.loc[(df1['away_name']=='The Draw') & (df1['ht'].str.lower()==df1['home_name'].str.lower()),'away_name']=df1['at']\n",
    "df1.loc[(df1['away_name']=='The Draw') & (df1['at'].str.lower()==df1['home_name'].str.lower()),'away_id']=df1['home_id']\n",
    "df1.loc[(df1['away_name']=='The Draw') & (df1['at'].str.lower()==df1['home_name'].str.lower()),'home_id']=df1['draw_id']\n",
    "df1.loc[(df1['away_name']=='The Draw') & (df1['at'].str.lower()==df1['home_name'].str.lower()),'home_name']=df1['ht']\n",
    "df1.loc[(df1['away_name']=='The Draw') & (df1['ht'].str.lower()==df1['home_name'].str.lower()),'away_name']=df1['at']\n",
    "df1.loc[(df1['home_name']=='The Draw') & (df1['at'].str.lower()==df1['away_name'].str.lower()),'home_id']=df1['draw_id']\n",
    "df1.loc[(df1['home_name']=='The Draw') & (df1['at'].str.lower()==df1['away_name'].str.lower()),'home_name']=df1['ht']\n",
    "df1.loc[(df1['home_name']=='The Draw') & (df1['ht'].str.lower()==df1['away_name'].str.lower()),'home_id']=df1['away_id']\n",
    "df1.loc[(df1['home_name']=='The Draw') & (df1['ht'].str.lower()==df1['away_name'].str.lower()),'away_id']=df1['draw_id']\n",
    "df1.loc[(df1['home_name']=='The Draw') & (df1['ht'].str.lower()==df1['away_name'].str.lower()),'away_name']=df1['at']\n",
    "df1.loc[(df1['home_name']=='The Draw') & (df1['at'].str.lower()==df1['away_name'].str.lower()),'home_name']=df1['ht']\n",
    "df=pd.concat([df1,df2], axis=0)\n",
    "df.dropna(subset=['inplayTime'], inplace=True)\n",
    "df=df[~((df['home_name']=='test1') | (df['away_name']=='test1') | (df['home_name']=='test2') | (df['away_name']=='test2'))]\n",
    "df=df[['eventId','countryCode','openDate','eventName','home_id','home_name','away_id','away_name','inplayTime','halfTime']]\n",
    "df.to_csv('data/bf_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/bf_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "cols=['eventId','clk','ltp','id','ip']\n",
    "cols_noid=['eventId','clk','ltp','ip']\n",
    "df_matches=pd.read_csv('data/bf/bf_matches.csv', index_col=None)\n",
    "for y in range(2015,2021):\n",
    "    dfs=[]\n",
    "    for f in glob.glob(path.join('data/bf/days/', f'{y}*_odds.csv')):\n",
    "        print(f)\n",
    "        dfs.append(pd.read_csv(f))\n",
    "        \n",
    "    df=pd.concat(dfs, axis=0)\n",
    "    df=df[df['eventId'].isin(df_matches['eventId'])]\n",
    "    df['ip']=0\n",
    "    df.loc[df['inplay'],'ip']=1\n",
    "    df=df[cols]\n",
    "    df_un=df.loc[df['id']==ID_UNDER][cols_noid]\n",
    "    df_ov=df.loc[df['id']==ID_OVER][cols_noid]\n",
    "    df_draw=df.loc[df['id']==ID_DRAW][cols_noid]\n",
    "    df_home=pd.merge(df,df_matches, left_on=['eventId','id'], right_on=['eventId','home_id'])[cols_noid]\n",
    "    df_away=pd.merge(df,df_matches, left_on=['eventId','id'], right_on=['eventId','away_id'])[cols_noid]\n",
    "    #df_12=df.loc[(df['id']!=ID_UNDER) & (df['id']!=ID_OVER) & (df['id']!=ID_DRAW)]\n",
    "    df_un.to_csv(f'data/bf_un_{y}.csv', index=False)\n",
    "    df_ov.to_csv(f'data/bf_ov_{y}.csv', index=False)\n",
    "    df_draw.to_csv(f'data/bf_draw_{y}.csv', index=False)\n",
    "    df_home.to_csv(f'data/bf_home_{y}.csv', index=False)\n",
    "    df_away.to_csv(f'data/bf_away_{y}.csv', index=False)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches=pd.read_csv('data/bf_matches.csv', index_col=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}